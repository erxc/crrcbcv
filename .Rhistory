for (i in 1:I) {
nu_i <- rstable(1,alpha=alpha,beta=1,gamma=(cos(alpha*pi/2))^(1/alpha),pm=1)
x_ij1 <- rnorm(1, mean=0, sd=1)
for (j in 1:J[i]) {
x_ij2 <- rnorm(1, mean=0, sd=1)
x_ij <- c(x_ij1, x_ij2)
p_ij <- 1-exp(-nu_i*exp(c(beta10%*%x_ij))) # zhou and others 2012
# p_ij <- 1-(1-p)^(nu_i*exp(c(beta10%*%x_ij))) # logan and others 2011
eps_ij <- 2-rbinom(1,1,p_ij)
U_2_ij <- runif(1)
if (eps_ij == 1) {
W_1 <- function(t) (1-exp(-nu_i*exp(c(beta10%*%x_ij))*(1-exp(-t))))/p_ij # zhou and others 2012
# W_1 <- function(t) (1-(1-p*(1-exp(-t)))^(nu_i*exp(c(beta10%*%x_ij))))/p_ij # logan and others 2012
W_1.inv <- inverse(W_1, lower=0)
T_ij <- W_1.inv(U_2_ij)
} else {
W_2 <- function(t) 1-exp(-t*exp(c(beta20%*%x_ij)))
W_2.inv <- inverse(W_2, lower=0)
T_ij <- W_2.inv(U_2_ij)
}
df_out[df_out$I==i & df_out$J_id==j, 'X_1'] <- x_ij1
df_out[df_out$I==i & df_out$J_id==j, 'X_2'] <- x_ij2
df_out[df_out$I==i & df_out$J_id==j, 'T_real'] <- T_ij
df_out[df_out$I==i & df_out$J_id==j, 'eps'] <- eps_ij
df_out[df_out$I==i & df_out$J_id==j, 'nu'] <- nu_i
}
}
# censoring
lam <- 0.35 # lam=0.35 for 20% censoring; 0.95 for 40% censoring
censoring_time <- rexp(nrow(df_out), rate=lam)
df_out[,'T_censor'] <- censoring_time
df_out[,'censor'] <- (df_out[,'T_censor'] <= df_out[,'T_real'])*1
df_out[,'T_obs'] <- pmin(df_out[,'T_censor'], df_out[,'T_real'])
df_out[,'eps'] <- df_out[,'eps']*(1-df_out[,'censor'])
return(df_out)
}
J <- round(rgamma(I, shape = CV^(-2), rate = mbar^(-1) * CV^(-2))) # cluster size
J <- J*(J>=2) + 2*(J<2) # the smallest cluster has size 2
# J <- mbar
df1 <- DataGen(I, J)
crrcsmv(ftime = df1$T_obs, fstatus = df1$eps, cov1 = df1[,c('X_1','X_2')],
cluster = df1$I, var.type = c("Robust", "MD"))
library(crrSCsmv)
rm(list = ls())
#########################
# Fixed true parameters #
#########################
library(crrSC)
# library(cmprsk)
library(pracma)
library(Rfast)
library(GoFKernel)
library(abind)
library(survival)
library(stabledist)
##################
# data structure #
##################
I <- 20 # number of clusters, I = 6, 8, 10, 20, 30
CV <- 0.5 # 0, 0.5
mbar <- 20 # 10, 20, 50
# J <- round(rgamma(I, shape = CV^(-2), rate = mbar^(-1) * CV^(-2))) # cluster size
# J <- J*(J>=2) + 2*(J<2) # the smallest cluster has size 2
# # J <- mbar
# Lambda10 <- function(t) { 1-exp(-t) } # baseline cumulative hazard function for risk 1
# Lambda20 <- function(t) { 1-exp(-0.8*t) } # baseline cumulative hazard function for risk 2
beta10 <- c(0.5, 0.5) # true value of coefficient vector for risk 1
beta20 <- c(0.2, 0.4) # true value of coefficient vector for risk 2
alpha <- 0.5 # 0.5, 0.9
# the residual-based bc method tends to over inflate variance when the cluster is larger
# but it performs better when the cluster is very small (5~10 participants in one cluster)
#####################################################################################
#####################################################################################
DataGen <- function(I, J){
if (length(J) > 1) {
# J_vec_tmp <- sample(J, I, replace=TRUE)
# J_vec <- unlist(sapply(J_vec_tmp, function(x) seq(1,x,by=1)))
J_vec <- unlist(sapply(J, function(x) seq(1,x,by=1)))
} else {
# J_vec_tmp <- rep(J, I)
J_vec <- rep(1:J, I)
}
I_vec <- rep(1:I, J)
df_out <- data.frame(I=I_vec, J_id=J_vec, X_1=rep(0,length(I_vec)),
X_2=rep(0,length(I_vec)), T_real=rep(0,length(I_vec)), eps=rep(0,length(I_vec)),
T_obs=rep(0,length(I_vec)), T_censor=rep(0,length(I_vec)), censor=rep(0,length(I_vec)),
nu=rep(0,length(I_vec)))
# p <- 0.5
for (i in 1:I) {
nu_i <- rstable(1,alpha=alpha,beta=1,gamma=(cos(alpha*pi/2))^(1/alpha),pm=1)
x_ij1 <- rnorm(1, mean=0, sd=1)
for (j in 1:J[i]) {
x_ij2 <- rnorm(1, mean=0, sd=1)
x_ij <- c(x_ij1, x_ij2)
p_ij <- 1-exp(-nu_i*exp(c(beta10%*%x_ij))) # zhou and others 2012
# p_ij <- 1-(1-p)^(nu_i*exp(c(beta10%*%x_ij))) # logan and others 2011
eps_ij <- 2-rbinom(1,1,p_ij)
U_2_ij <- runif(1)
if (eps_ij == 1) {
W_1 <- function(t) (1-exp(-nu_i*exp(c(beta10%*%x_ij))*(1-exp(-t))))/p_ij # zhou and others 2012
# W_1 <- function(t) (1-(1-p*(1-exp(-t)))^(nu_i*exp(c(beta10%*%x_ij))))/p_ij # logan and others 2012
W_1.inv <- inverse(W_1, lower=0)
T_ij <- W_1.inv(U_2_ij)
} else {
W_2 <- function(t) 1-exp(-t*exp(c(beta20%*%x_ij)))
W_2.inv <- inverse(W_2, lower=0)
T_ij <- W_2.inv(U_2_ij)
}
df_out[df_out$I==i & df_out$J_id==j, 'X_1'] <- x_ij1
df_out[df_out$I==i & df_out$J_id==j, 'X_2'] <- x_ij2
df_out[df_out$I==i & df_out$J_id==j, 'T_real'] <- T_ij
df_out[df_out$I==i & df_out$J_id==j, 'eps'] <- eps_ij
df_out[df_out$I==i & df_out$J_id==j, 'nu'] <- nu_i
}
}
# censoring
lam <- 0.35 # lam=0.35 for 20% censoring; 0.95 for 40% censoring
censoring_time <- rexp(nrow(df_out), rate=lam)
df_out[,'T_censor'] <- censoring_time
df_out[,'censor'] <- (df_out[,'T_censor'] <= df_out[,'T_real'])*1
df_out[,'T_obs'] <- pmin(df_out[,'T_censor'], df_out[,'T_real'])
df_out[,'eps'] <- df_out[,'eps']*(1-df_out[,'censor'])
return(df_out)
}
J <- round(rgamma(I, shape = CV^(-2), rate = mbar^(-1) * CV^(-2))) # cluster size
J <- J*(J>=2) + 2*(J<2) # the smallest cluster has size 2
# J <- mbar
df1 <- DataGen(I, J)
beta.est <- crrc(ftime=df1$T_obs, fstatus=df1$eps, cov1=df1[,c('X_1','X_2')], cluster=ID)
beta.est <- crrc(ftime=df1$T_obs, fstatus=df1$eps, cov1=df1[,c('X_1','X_2')], cluster=df1$I)
beta_k <- beta.est$coef
beta_k
crrcsmv(beta_k=beta_k, ftime = df1$T_obs, fstatus = df1$eps, cov1 = df1[,c('X_1','X_2')],
cluster = df1$I, var.type = "MD")
library(devtools)
install()
library(crrSCsmv)
rm(list = ls())
#########################
# Fixed true parameters #
#########################
library(crrSC)
# library(cmprsk)
library(pracma)
library(Rfast)
library(GoFKernel)
library(abind)
library(survival)
library(stabledist)
##################
# data structure #
##################
I <- 20 # number of clusters, I = 6, 8, 10, 20, 30
CV <- 0.5 # 0, 0.5
mbar <- 20 # 10, 20, 50
# J <- round(rgamma(I, shape = CV^(-2), rate = mbar^(-1) * CV^(-2))) # cluster size
# J <- J*(J>=2) + 2*(J<2) # the smallest cluster has size 2
# # J <- mbar
# Lambda10 <- function(t) { 1-exp(-t) } # baseline cumulative hazard function for risk 1
# Lambda20 <- function(t) { 1-exp(-0.8*t) } # baseline cumulative hazard function for risk 2
beta10 <- c(0.5, 0.5) # true value of coefficient vector for risk 1
beta20 <- c(0.2, 0.4) # true value of coefficient vector for risk 2
alpha <- 0.5 # 0.5, 0.9
# the residual-based bc method tends to over inflate variance when the cluster is larger
# but it performs better when the cluster is very small (5~10 participants in one cluster)
#####################################################################################
#####################################################################################
DataGen <- function(I, J){
if (length(J) > 1) {
# J_vec_tmp <- sample(J, I, replace=TRUE)
# J_vec <- unlist(sapply(J_vec_tmp, function(x) seq(1,x,by=1)))
J_vec <- unlist(sapply(J, function(x) seq(1,x,by=1)))
} else {
# J_vec_tmp <- rep(J, I)
J_vec <- rep(1:J, I)
}
I_vec <- rep(1:I, J)
df_out <- data.frame(I=I_vec, J_id=J_vec, X_1=rep(0,length(I_vec)),
X_2=rep(0,length(I_vec)), T_real=rep(0,length(I_vec)), eps=rep(0,length(I_vec)),
T_obs=rep(0,length(I_vec)), T_censor=rep(0,length(I_vec)), censor=rep(0,length(I_vec)),
nu=rep(0,length(I_vec)))
# p <- 0.5
for (i in 1:I) {
nu_i <- rstable(1,alpha=alpha,beta=1,gamma=(cos(alpha*pi/2))^(1/alpha),pm=1)
x_ij1 <- rnorm(1, mean=0, sd=1)
for (j in 1:J[i]) {
x_ij2 <- rnorm(1, mean=0, sd=1)
x_ij <- c(x_ij1, x_ij2)
p_ij <- 1-exp(-nu_i*exp(c(beta10%*%x_ij))) # zhou and others 2012
# p_ij <- 1-(1-p)^(nu_i*exp(c(beta10%*%x_ij))) # logan and others 2011
eps_ij <- 2-rbinom(1,1,p_ij)
U_2_ij <- runif(1)
if (eps_ij == 1) {
W_1 <- function(t) (1-exp(-nu_i*exp(c(beta10%*%x_ij))*(1-exp(-t))))/p_ij # zhou and others 2012
# W_1 <- function(t) (1-(1-p*(1-exp(-t)))^(nu_i*exp(c(beta10%*%x_ij))))/p_ij # logan and others 2012
W_1.inv <- inverse(W_1, lower=0)
T_ij <- W_1.inv(U_2_ij)
} else {
W_2 <- function(t) 1-exp(-t*exp(c(beta20%*%x_ij)))
W_2.inv <- inverse(W_2, lower=0)
T_ij <- W_2.inv(U_2_ij)
}
df_out[df_out$I==i & df_out$J_id==j, 'X_1'] <- x_ij1
df_out[df_out$I==i & df_out$J_id==j, 'X_2'] <- x_ij2
df_out[df_out$I==i & df_out$J_id==j, 'T_real'] <- T_ij
df_out[df_out$I==i & df_out$J_id==j, 'eps'] <- eps_ij
df_out[df_out$I==i & df_out$J_id==j, 'nu'] <- nu_i
}
}
# censoring
lam <- 0.35 # lam=0.35 for 20% censoring; 0.95 for 40% censoring
censoring_time <- rexp(nrow(df_out), rate=lam)
df_out[,'T_censor'] <- censoring_time
df_out[,'censor'] <- (df_out[,'T_censor'] <= df_out[,'T_real'])*1
df_out[,'T_obs'] <- pmin(df_out[,'T_censor'], df_out[,'T_real'])
df_out[,'eps'] <- df_out[,'eps']*(1-df_out[,'censor'])
return(df_out)
}
J <- round(rgamma(I, shape = CV^(-2), rate = mbar^(-1) * CV^(-2))) # cluster size
J <- J*(J>=2) + 2*(J<2) # the smallest cluster has size 2
# J <- mbar
df1 <- DataGen(I, J)
beta.est <- crrc(ftime=df1$T_obs, fstatus=df1$eps, cov1=df1[,c('X_1','X_2')], cluster=df1$I)
beta_k <- beta.est$coef
document()
?crrcsmv
crrcsmv(beta_k=beta_k, ftime = df1$T_obs, fstatus = df1$eps, cov1 = df1[,c('X_1','X_2')],
cluster = df1$I, var.type = "MD")
library(devtools)
install()
library(crrSCsmv)
rm(list = ls())
#########################
# Fixed true parameters #
#########################
library(crrSC)
# library(cmprsk)
library(pracma)
library(Rfast)
library(GoFKernel)
library(abind)
library(survival)
library(stabledist)
##################
# data structure #
##################
I <- 20 # number of clusters, I = 6, 8, 10, 20, 30
CV <- 0.5 # 0, 0.5
mbar <- 20 # 10, 20, 50
# J <- round(rgamma(I, shape = CV^(-2), rate = mbar^(-1) * CV^(-2))) # cluster size
# J <- J*(J>=2) + 2*(J<2) # the smallest cluster has size 2
# # J <- mbar
# Lambda10 <- function(t) { 1-exp(-t) } # baseline cumulative hazard function for risk 1
# Lambda20 <- function(t) { 1-exp(-0.8*t) } # baseline cumulative hazard function for risk 2
beta10 <- c(0.5, 0.5) # true value of coefficient vector for risk 1
beta20 <- c(0.2, 0.4) # true value of coefficient vector for risk 2
alpha <- 0.5 # 0.5, 0.9
# the residual-based bc method tends to over inflate variance when the cluster is larger
# but it performs better when the cluster is very small (5~10 participants in one cluster)
#####################################################################################
#####################################################################################
DataGen <- function(I, J){
if (length(J) > 1) {
# J_vec_tmp <- sample(J, I, replace=TRUE)
# J_vec <- unlist(sapply(J_vec_tmp, function(x) seq(1,x,by=1)))
J_vec <- unlist(sapply(J, function(x) seq(1,x,by=1)))
} else {
# J_vec_tmp <- rep(J, I)
J_vec <- rep(1:J, I)
}
I_vec <- rep(1:I, J)
df_out <- data.frame(I=I_vec, J_id=J_vec, X_1=rep(0,length(I_vec)),
X_2=rep(0,length(I_vec)), T_real=rep(0,length(I_vec)), eps=rep(0,length(I_vec)),
T_obs=rep(0,length(I_vec)), T_censor=rep(0,length(I_vec)), censor=rep(0,length(I_vec)),
nu=rep(0,length(I_vec)))
# p <- 0.5
for (i in 1:I) {
nu_i <- rstable(1,alpha=alpha,beta=1,gamma=(cos(alpha*pi/2))^(1/alpha),pm=1)
x_ij1 <- rnorm(1, mean=0, sd=1)
for (j in 1:J[i]) {
x_ij2 <- rnorm(1, mean=0, sd=1)
x_ij <- c(x_ij1, x_ij2)
p_ij <- 1-exp(-nu_i*exp(c(beta10%*%x_ij))) # zhou and others 2012
# p_ij <- 1-(1-p)^(nu_i*exp(c(beta10%*%x_ij))) # logan and others 2011
eps_ij <- 2-rbinom(1,1,p_ij)
U_2_ij <- runif(1)
if (eps_ij == 1) {
W_1 <- function(t) (1-exp(-nu_i*exp(c(beta10%*%x_ij))*(1-exp(-t))))/p_ij # zhou and others 2012
# W_1 <- function(t) (1-(1-p*(1-exp(-t)))^(nu_i*exp(c(beta10%*%x_ij))))/p_ij # logan and others 2012
W_1.inv <- inverse(W_1, lower=0)
T_ij <- W_1.inv(U_2_ij)
} else {
W_2 <- function(t) 1-exp(-t*exp(c(beta20%*%x_ij)))
W_2.inv <- inverse(W_2, lower=0)
T_ij <- W_2.inv(U_2_ij)
}
df_out[df_out$I==i & df_out$J_id==j, 'X_1'] <- x_ij1
df_out[df_out$I==i & df_out$J_id==j, 'X_2'] <- x_ij2
df_out[df_out$I==i & df_out$J_id==j, 'T_real'] <- T_ij
df_out[df_out$I==i & df_out$J_id==j, 'eps'] <- eps_ij
df_out[df_out$I==i & df_out$J_id==j, 'nu'] <- nu_i
}
}
# censoring
lam <- 0.35 # lam=0.35 for 20% censoring; 0.95 for 40% censoring
censoring_time <- rexp(nrow(df_out), rate=lam)
df_out[,'T_censor'] <- censoring_time
df_out[,'censor'] <- (df_out[,'T_censor'] <= df_out[,'T_real'])*1
df_out[,'T_obs'] <- pmin(df_out[,'T_censor'], df_out[,'T_real'])
df_out[,'eps'] <- df_out[,'eps']*(1-df_out[,'censor'])
return(df_out)
}
J <- round(rgamma(I, shape = CV^(-2), rate = mbar^(-1) * CV^(-2))) # cluster size
J <- J*(J>=2) + 2*(J<2) # the smallest cluster has size 2
# J <- mbar
df1 <- DataGen(I, J)
beta.est <- crrc(ftime=df1$T_obs, fstatus=df1$eps, cov1=df1[,c('X_1','X_2')], cluster=df1$I)
beta_k <- beta.est$coef
crrcsmv(beta_k=beta_k, ftime = df1$T_obs, fstatus = df1$eps, cov1 = df1[,c('X_1','X_2')],
cluster = df1$I, var.type = "MD")
library(devtools)
install()
library(crrSCsmv)
rm(list = ls())
#########################
# Fixed true parameters #
#########################
library(crrSC)
# library(cmprsk)
library(pracma)
library(Rfast)
library(GoFKernel)
library(abind)
library(survival)
library(stabledist)
##################
# data structure #
##################
I <- 20 # number of clusters, I = 6, 8, 10, 20, 30
CV <- 0.5 # 0, 0.5
mbar <- 20 # 10, 20, 50
# J <- round(rgamma(I, shape = CV^(-2), rate = mbar^(-1) * CV^(-2))) # cluster size
# J <- J*(J>=2) + 2*(J<2) # the smallest cluster has size 2
# # J <- mbar
# Lambda10 <- function(t) { 1-exp(-t) } # baseline cumulative hazard function for risk 1
# Lambda20 <- function(t) { 1-exp(-0.8*t) } # baseline cumulative hazard function for risk 2
beta10 <- c(0.5, 0.5) # true value of coefficient vector for risk 1
beta20 <- c(0.2, 0.4) # true value of coefficient vector for risk 2
alpha <- 0.5 # 0.5, 0.9
# the residual-based bc method tends to over inflate variance when the cluster is larger
# but it performs better when the cluster is very small (5~10 participants in one cluster)
#####################################################################################
#####################################################################################
DataGen <- function(I, J){
if (length(J) > 1) {
# J_vec_tmp <- sample(J, I, replace=TRUE)
# J_vec <- unlist(sapply(J_vec_tmp, function(x) seq(1,x,by=1)))
J_vec <- unlist(sapply(J, function(x) seq(1,x,by=1)))
} else {
# J_vec_tmp <- rep(J, I)
J_vec <- rep(1:J, I)
}
I_vec <- rep(1:I, J)
df_out <- data.frame(I=I_vec, J_id=J_vec, X_1=rep(0,length(I_vec)),
X_2=rep(0,length(I_vec)), T_real=rep(0,length(I_vec)), eps=rep(0,length(I_vec)),
T_obs=rep(0,length(I_vec)), T_censor=rep(0,length(I_vec)), censor=rep(0,length(I_vec)),
nu=rep(0,length(I_vec)))
# p <- 0.5
for (i in 1:I) {
nu_i <- rstable(1,alpha=alpha,beta=1,gamma=(cos(alpha*pi/2))^(1/alpha),pm=1)
x_ij1 <- rnorm(1, mean=0, sd=1)
for (j in 1:J[i]) {
x_ij2 <- rnorm(1, mean=0, sd=1)
x_ij <- c(x_ij1, x_ij2)
p_ij <- 1-exp(-nu_i*exp(c(beta10%*%x_ij))) # zhou and others 2012
# p_ij <- 1-(1-p)^(nu_i*exp(c(beta10%*%x_ij))) # logan and others 2011
eps_ij <- 2-rbinom(1,1,p_ij)
U_2_ij <- runif(1)
if (eps_ij == 1) {
W_1 <- function(t) (1-exp(-nu_i*exp(c(beta10%*%x_ij))*(1-exp(-t))))/p_ij # zhou and others 2012
# W_1 <- function(t) (1-(1-p*(1-exp(-t)))^(nu_i*exp(c(beta10%*%x_ij))))/p_ij # logan and others 2012
W_1.inv <- inverse(W_1, lower=0)
T_ij <- W_1.inv(U_2_ij)
} else {
W_2 <- function(t) 1-exp(-t*exp(c(beta20%*%x_ij)))
W_2.inv <- inverse(W_2, lower=0)
T_ij <- W_2.inv(U_2_ij)
}
df_out[df_out$I==i & df_out$J_id==j, 'X_1'] <- x_ij1
df_out[df_out$I==i & df_out$J_id==j, 'X_2'] <- x_ij2
df_out[df_out$I==i & df_out$J_id==j, 'T_real'] <- T_ij
df_out[df_out$I==i & df_out$J_id==j, 'eps'] <- eps_ij
df_out[df_out$I==i & df_out$J_id==j, 'nu'] <- nu_i
}
}
# censoring
lam <- 0.35 # lam=0.35 for 20% censoring; 0.95 for 40% censoring
censoring_time <- rexp(nrow(df_out), rate=lam)
df_out[,'T_censor'] <- censoring_time
df_out[,'censor'] <- (df_out[,'T_censor'] <= df_out[,'T_real'])*1
df_out[,'T_obs'] <- pmin(df_out[,'T_censor'], df_out[,'T_real'])
df_out[,'eps'] <- df_out[,'eps']*(1-df_out[,'censor'])
return(df_out)
}
J <- round(rgamma(I, shape = CV^(-2), rate = mbar^(-1) * CV^(-2))) # cluster size
J <- J*(J>=2) + 2*(J<2) # the smallest cluster has size 2
# J <- mbar
df1 <- DataGen(I, J)
beta.est <- crrc(ftime=df1$T_obs, fstatus=df1$eps, cov1=df1[,c('X_1','X_2')], cluster=df1$I)
beta_k <- beta.est$coef
crrcsmv(beta_k=beta_k, ftime = df1$T_obs, fstatus = df1$eps, cov1 = df1[,c('X_1','X_2')],
cluster = df1$I, var.type = "MD")
sqrt(diag(beta.est$var))
crrcsmv(beta_k=beta_k, ftime = df1$T_obs, fstatus = df1$eps,
cluster = df1$I, var.type = "MD")
library(devtools)
install()
library(crrSCsmv)
rm(list = ls())
#########################
# Fixed true parameters #
#########################
library(crrSC)
# library(cmprsk)
library(pracma)
library(Rfast)
library(GoFKernel)
library(abind)
library(survival)
library(stabledist)
##################
# data structure #
##################
I <- 20 # number of clusters, I = 6, 8, 10, 20, 30
CV <- 0.5 # 0, 0.5
mbar <- 20 # 10, 20, 50
# J <- round(rgamma(I, shape = CV^(-2), rate = mbar^(-1) * CV^(-2))) # cluster size
# J <- J*(J>=2) + 2*(J<2) # the smallest cluster has size 2
# # J <- mbar
# Lambda10 <- function(t) { 1-exp(-t) } # baseline cumulative hazard function for risk 1
# Lambda20 <- function(t) { 1-exp(-0.8*t) } # baseline cumulative hazard function for risk 2
beta10 <- c(0.5, 0.5) # true value of coefficient vector for risk 1
beta20 <- c(0.2, 0.4) # true value of coefficient vector for risk 2
alpha <- 0.5 # 0.5, 0.9
# the residual-based bc method tends to over inflate variance when the cluster is larger
# but it performs better when the cluster is very small (5~10 participants in one cluster)
#####################################################################################
#####################################################################################
DataGen <- function(I, J){
if (length(J) > 1) {
# J_vec_tmp <- sample(J, I, replace=TRUE)
# J_vec <- unlist(sapply(J_vec_tmp, function(x) seq(1,x,by=1)))
J_vec <- unlist(sapply(J, function(x) seq(1,x,by=1)))
} else {
# J_vec_tmp <- rep(J, I)
J_vec <- rep(1:J, I)
}
I_vec <- rep(1:I, J)
df_out <- data.frame(I=I_vec, J_id=J_vec, X_1=rep(0,length(I_vec)),
X_2=rep(0,length(I_vec)), T_real=rep(0,length(I_vec)), eps=rep(0,length(I_vec)),
T_obs=rep(0,length(I_vec)), T_censor=rep(0,length(I_vec)), censor=rep(0,length(I_vec)),
nu=rep(0,length(I_vec)))
# p <- 0.5
for (i in 1:I) {
nu_i <- rstable(1,alpha=alpha,beta=1,gamma=(cos(alpha*pi/2))^(1/alpha),pm=1)
x_ij1 <- rnorm(1, mean=0, sd=1)
for (j in 1:J[i]) {
x_ij2 <- rnorm(1, mean=0, sd=1)
x_ij <- c(x_ij1, x_ij2)
p_ij <- 1-exp(-nu_i*exp(c(beta10%*%x_ij))) # zhou and others 2012
# p_ij <- 1-(1-p)^(nu_i*exp(c(beta10%*%x_ij))) # logan and others 2011
eps_ij <- 2-rbinom(1,1,p_ij)
U_2_ij <- runif(1)
if (eps_ij == 1) {
W_1 <- function(t) (1-exp(-nu_i*exp(c(beta10%*%x_ij))*(1-exp(-t))))/p_ij # zhou and others 2012
# W_1 <- function(t) (1-(1-p*(1-exp(-t)))^(nu_i*exp(c(beta10%*%x_ij))))/p_ij # logan and others 2012
W_1.inv <- inverse(W_1, lower=0)
T_ij <- W_1.inv(U_2_ij)
} else {
W_2 <- function(t) 1-exp(-t*exp(c(beta20%*%x_ij)))
W_2.inv <- inverse(W_2, lower=0)
T_ij <- W_2.inv(U_2_ij)
}
df_out[df_out$I==i & df_out$J_id==j, 'X_1'] <- x_ij1
df_out[df_out$I==i & df_out$J_id==j, 'X_2'] <- x_ij2
df_out[df_out$I==i & df_out$J_id==j, 'T_real'] <- T_ij
df_out[df_out$I==i & df_out$J_id==j, 'eps'] <- eps_ij
df_out[df_out$I==i & df_out$J_id==j, 'nu'] <- nu_i
}
}
# censoring
lam <- 0.35 # lam=0.35 for 20% censoring; 0.95 for 40% censoring
censoring_time <- rexp(nrow(df_out), rate=lam)
df_out[,'T_censor'] <- censoring_time
df_out[,'censor'] <- (df_out[,'T_censor'] <= df_out[,'T_real'])*1
df_out[,'T_obs'] <- pmin(df_out[,'T_censor'], df_out[,'T_real'])
df_out[,'eps'] <- df_out[,'eps']*(1-df_out[,'censor'])
return(df_out)
}
J <- round(rgamma(I, shape = CV^(-2), rate = mbar^(-1) * CV^(-2))) # cluster size
J <- J*(J>=2) + 2*(J<2) # the smallest cluster has size 2
# J <- mbar
df1 <- DataGen(I, J)
beta.est <- crrc(ftime=df1$T_obs, fstatus=df1$eps, cov1=df1[,c('X_1','X_2')], cluster=df1$I)
beta_k <- beta.est$coef
crrcsmv(beta_k=beta_k, ftime = df1$T_obs, fstatus = df1$eps, cov1 = df1[,c('X_1','X_2')],
cluster = df1$I, var.type = c("MD", "KC", "FG", "MBN"))
document()
?crrcsmv
use_github(protocol='ssh')
use_github()
use_git()
